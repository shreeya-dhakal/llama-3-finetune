{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Fine-tune multi-lingual - with both Hindi and Nepali\n- Fine tune with Hindi run inference on Nepali \n- Fine tune with Nepali run inference on Hindi\n- Fine tune with Nepali run inference on Nepali\n- Fine tune with Hindi run inference on Hindi","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:12:22.574079Z","iopub.execute_input":"2024-07-19T03:12:22.574721Z","iopub.status.idle":"2024-07-19T03:12:22.590922Z","shell.execute_reply.started":"2024-07-19T03:12:22.574684Z","shell.execute_reply":"2024-07-19T03:12:22.590190Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"GITHUB_KEY\")","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:12:24.738285Z","iopub.execute_input":"2024-07-19T03:12:24.738942Z","iopub.status.idle":"2024-07-19T03:12:24.879288Z","shell.execute_reply.started":"2024-07-19T03:12:24.738911Z","shell.execute_reply":"2024-07-19T03:12:24.878535Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!git clone https://{token}@github.com/shreeya-dhakal/llama-3-finetune.git","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:12:26.909487Z","iopub.execute_input":"2024-07-19T03:12:26.910173Z","iopub.status.idle":"2024-07-19T03:12:31.305072Z","shell.execute_reply.started":"2024-07-19T03:12:26.910141Z","shell.execute_reply":"2024-07-19T03:12:31.304189Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'llama-3-finetune'...\nremote: Enumerating objects: 137, done.\u001b[K\nremote: Counting objects: 100% (137/137), done.\u001b[K\nremote: Compressing objects: 100% (110/110), done.\u001b[K\nremote: Total 137 (delta 69), reused 73 (delta 19), pack-reused 0\u001b[K\nReceiving objects: 100% (137/137), 27.97 MiB | 18.17 MiB/s, done.\nResolving deltas: 100% (69/69), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!mamba install --force-reinstall aiohttp -y\n!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:12:57.198244Z","iopub.execute_input":"2024-07-19T03:12:57.199258Z","iopub.status.idle":"2024-07-19T03:17:43.685855Z","shell.execute_reply.started":"2024-07-19T03:12:57.199221Z","shell.execute_reply":"2024-07-19T03:17:43.684831Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport wandb\n\nos.environ[\"WANDB_PROJECT\"]=\"llama-finetune-nepali-alpaca\" # Change this\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\nwandb_token = user_secrets.get_secret(\"WANDB_KEY\")\nwandb.login(key= wandb_token)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:21:29.993010Z","iopub.execute_input":"2024-07-19T03:21:29.993736Z","iopub.status.idle":"2024-07-19T03:21:33.319737Z","shell.execute_reply.started":"2024-07-19T03:21:29.993699Z","shell.execute_reply":"2024-07-19T03:21:33.318920Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric, concatenate_datasets\nimport sys\nimport os\nsys.path.append('/kaggle/working/llama-3-finetune/src/')\nfrom data.data_sampler import sample_data\nfrom unsloth import FastLanguageModel\nimport torch\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:21:35.618200Z","iopub.execute_input":"2024-07-19T03:21:35.618781Z","iopub.status.idle":"2024-07-19T03:21:58.120701Z","shell.execute_reply.started":"2024-07-19T03:21:35.618739Z","shell.execute_reply":"2024-07-19T03:21:58.119914Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2024-07-19 03:21:46.816518: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-19 03:21:46.816608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-19 03:21:46.997396: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"split_ratio = 0.2\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:22:06.071477Z","iopub.execute_input":"2024-07-19T03:22:06.072930Z","iopub.status.idle":"2024-07-19T03:22:06.077159Z","shell.execute_reply.started":"2024-07-19T03:22:06.072884Z","shell.execute_reply":"2024-07-19T03:22:06.076319Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# dataset_name = \"CohereForAI/aya_dataset\"\n# aya_dataset = load_dataset(dataset_name)\n# dataset_type = \"aya\"","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:10.393712Z","iopub.execute_input":"2024-06-23T16:58:10.394541Z","iopub.status.idle":"2024-06-23T16:58:17.373146Z","shell.execute_reply.started":"2024-06-23T16:58:10.394499Z","shell.execute_reply":"2024-06-23T16:58:17.372321Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/13.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f65eff9cf0c343ea836a6faddcd862df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/137M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d229c7cac44c1dbb4718836e0037ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/978k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdf787317b2d449eb1cd7e86e06cbfa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d2f96adee4496da3e65d734ea2596b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93622575176a4ba7ae82226a63bbd56b"}},"metadata":{}}]},{"cell_type":"code","source":"# lang_multi = \"Nepali\"\n# aya_nepali_train, _ = sample_data(dataset_name, dataset_type, split_ratio, seed, output_dir=None, lang_multi=lang_multi)\n# aya_nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:19.258395Z","iopub.execute_input":"2024-06-23T16:58:19.259155Z","iopub.status.idle":"2024-06-23T16:58:24.463532Z","shell.execute_reply.started":"2024-06-23T16:58:19.259123Z","shell.execute_reply":"2024-06-23T16:58:24.462699Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2192a349c4ac424c8b64f253fd988134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71f08150a59418d9c5aeb02b488a24a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1074a3666247460a83feda229bbf827a"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n    num_rows: 3201\n})"},"metadata":{}}]},{"cell_type":"code","source":"# lang_multi = \"Hindi\"\n# aya_hindi_train, _ = sample_data(dataset_name, dataset_type, split_ratio, seed, output_dir=None, lang_multi=lang_multi)\n# aya_hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:25.958499Z","iopub.execute_input":"2024-06-23T16:58:25.959521Z","iopub.status.idle":"2024-06-23T16:58:30.631657Z","shell.execute_reply.started":"2024-06-23T16:58:25.959484Z","shell.execute_reply":"2024-06-23T16:58:30.630788Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c3659b985ed4b4486b6c251dbc99a7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4e51e5d17548548dd31d3eea58397c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1153 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c649ecd2ecff414c94f4630c1ed308de"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n    num_rows: 922\n})"},"metadata":{}}]},{"cell_type":"code","source":"# aya_nepali_train = aya_nepali_train.rename_columns(\n#             {\"inputs\": \"input\", \"targets\": \"output\"})\n# new_column_data = [\"\"] * len(aya_nepali_train)  # Create a list with the same length as the dataset\n# aya_nepali_train = aya_nepali_train.add_column(\"instruction\", new_column_data)\n# aya_nepali_train = aya_nepali_train.remove_columns(['language', 'language_code', 'annotation_type', 'user_id'])\n# aya_nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:32.564002Z","iopub.execute_input":"2024-06-23T16:58:32.564392Z","iopub.status.idle":"2024-06-23T16:58:32.801239Z","shell.execute_reply.started":"2024-06-23T16:58:32.564359Z","shell.execute_reply":"2024-06-23T16:58:32.800326Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/3201 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0696c9cb6a417294c6075b2d4bfe7f"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 3201\n})"},"metadata":{}}]},{"cell_type":"code","source":"# aya_hindi_train = aya_hindi_train.rename_columns(\n#             {\"inputs\": \"input\", \"targets\": \"output\"})\n# new_column_data = [\"\"] * len(aya_hindi_train)\n# aya_hindi_train = aya_hindi_train.add_column(\"instruction\", new_column_data)\n# aya_hindi_train = aya_hindi_train.remove_columns(['language', 'language_code', 'annotation_type', 'user_id'])\n# aya_hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:36.055550Z","iopub.execute_input":"2024-06-23T16:58:36.056416Z","iopub.status.idle":"2024-06-23T16:58:36.110181Z","shell.execute_reply.started":"2024-06-23T16:58:36.056384Z","shell.execute_reply":"2024-06-23T16:58:36.109326Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/922 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3023715250c746a0b1fdf1651c90811f"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 922\n})"},"metadata":{}}]},{"cell_type":"code","source":"# dataset_name = \"Saugatkafley/alpaca-nepali-sft\"","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:22:16.465826Z","iopub.execute_input":"2024-07-19T03:22:16.466661Z","iopub.status.idle":"2024-07-19T03:22:16.470685Z","shell.execute_reply.started":"2024-07-19T03:22:16.466602Z","shell.execute_reply":"2024-07-19T03:22:16.469786Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# alpaca_nepali_train, _ = sample_data(dataset_name, \"alpaca\", split_ratio, seed, output_dir=None, lang_multi=None)\n# alpaca_nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:22:21.979160Z","iopub.execute_input":"2024-07-19T03:22:21.979817Z","iopub.status.idle":"2024-07-19T03:22:27.902413Z","shell.execute_reply.started":"2024-07-19T03:22:21.979784Z","shell.execute_reply":"2024-07-19T03:22:27.901438Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2cefdad0e5942079856875bf8e75d06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/18.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"394833f0eb654b19be711c231de78d14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/52005 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2fdc26e1e841c7b40dda0a7339be05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/52005 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe72543ba8d74643a855e1bfdd5d1c12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51963 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c674c308f31e4718ac66c3ee7f2253df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51963 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0edcba2cb373457580f0ee9772313396"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output', 'id'],\n    num_rows: 41567\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_name = \"iamshnoo/alpaca-cleaned-hindi\"","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:49.828165Z","iopub.execute_input":"2024-06-23T16:58:49.828554Z","iopub.status.idle":"2024-06-23T16:58:49.832995Z","shell.execute_reply.started":"2024-06-23T16:58:49.828521Z","shell.execute_reply":"2024-06-23T16:58:49.832035Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"alpaca_hindi_train, _ = sample_data(dataset_name, \"alpaca\", split_ratio, seed, output_dir=None, lang_multi=None)\nalpaca_hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:58:52.359435Z","iopub.execute_input":"2024-06-23T16:58:52.360140Z","iopub.status.idle":"2024-06-23T16:58:58.612253Z","shell.execute_reply.started":"2024-06-23T16:58:52.360106Z","shell.execute_reply":"2024-06-23T16:58:58.611347Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbeec1d53f084106a5248a39ae81c846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/31.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e48ac6f63bee4233a78675504f72c7b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c3b384833e4d349b81cfd6b6c3deb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30653d9a547942658fc36fc022c299c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa153fb152fc4339bb6a002c5d22e91f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"089bc6e62d384972a395db720fe65555"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'instruction', 'output'],\n    num_rows: 41408\n})"},"metadata":{}}]},{"cell_type":"code","source":"# nepali_train = concatenate_datasets([aya_nepali_train, alpaca_nepali_train])\n# nepali_train = nepali_train.shuffle(seed=42)\n# nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:59:55.148266Z","iopub.execute_input":"2024-06-23T16:59:55.148685Z","iopub.status.idle":"2024-06-23T16:59:55.188467Z","shell.execute_reply.started":"2024-06-23T16:59:55.148653Z","shell.execute_reply":"2024-06-23T16:59:55.187600Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction', 'id'],\n    num_rows: 44768\n})"},"metadata":{}}]},{"cell_type":"code","source":"# hindi_train = concatenate_datasets([aya_hindi_train, alpaca_hindi_train])\n# hindi_train = hindi_train.shuffle(seed=42)\n# hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-06-23T16:59:57.381044Z","iopub.execute_input":"2024-06-23T16:59:57.381459Z","iopub.status.idle":"2024-06-23T16:59:57.418667Z","shell.execute_reply.started":"2024-06-23T16:59:57.381427Z","shell.execute_reply":"2024-06-23T16:59:57.417693Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 42330\n})"},"metadata":{}}]},{"cell_type":"code","source":"# both_train = concatenate_datasets([nepali_train, hindi_train])\n# both_train = both_train.shuffle(seed=42)\n# both_train","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:27:54.097038Z","iopub.execute_input":"2024-06-16T21:27:54.097298Z","iopub.status.idle":"2024-06-16T21:27:54.101014Z","shell.execute_reply.started":"2024-06-16T21:27:54.097276Z","shell.execute_reply":"2024-06-16T21:27:54.100143Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# #Nepali\n# prompt = \"\"\"Below is an instruction in Nepali that describes a task, paired with an input also in Nepali that provides further context. Write a response in Nepali that appropriately completes the request.\n\n# ### Instruction:\n# {}\n\n# ### Input:\n# {}\n\n# ### Response:\n# {}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:22:38.911702Z","iopub.execute_input":"2024-07-19T03:22:38.912030Z","iopub.status.idle":"2024-07-19T03:22:38.916516Z","shell.execute_reply.started":"2024-07-19T03:22:38.912007Z","shell.execute_reply":"2024-07-19T03:22:38.915554Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Hindi\nprompt = \"\"\"Below is an instruction in Hindi that describes a task, paired with an input also in Hindi that provides further context. Write a response in Hindi that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)\n\ntokenizer.add_special_tokens({\"pad_token\": \"<|reserved_special_token_0|>\"})\nmodel.config.pad_token_id = tokenizer.pad_token_id\ntokenizer.padding_side = 'right'","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:22:41.778853Z","iopub.execute_input":"2024-07-19T03:22:41.779209Z","iopub.status.idle":"2024-07-19T03:23:19.637010Z","shell.execute_reply.started":"2024-07-19T03:22:41.779180Z","shell.execute_reply":"2024-07-19T03:23:19.635856Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"256386b805f441dfb47f68abf5df2ea1"}},"metadata":{}},{"name":"stderr","text":"Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"name":"stdout","text":"==((====))==  Unsloth: Fast Llama patching release 2024.7\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.25.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c7b6ec6d4e3450ea8442df2621c6a62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e504adf26e44390a3695d424f89d762"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099db1333c994d5aacf48ee3aa837305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b60b443a021140f4b258f58332d638d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/464 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9a8a974d9df43e3952409131c1576e1"}},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Pad Token id: {tokenizer.pad_token_id} and Pad Token: {tokenizer.pad_token}\")\nprint(f\"EOS Token id: {tokenizer.eos_token_id} and EOS Token: {tokenizer.eos_token}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:23:28.438128Z","iopub.execute_input":"2024-07-19T03:23:28.438488Z","iopub.status.idle":"2024-07-19T03:23:28.443603Z","shell.execute_reply.started":"2024-07-19T03:23:28.438459Z","shell.execute_reply":"2024-07-19T03:23:28.442705Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Pad Token id: 128002 and Pad Token: <|reserved_special_token_0|>\nEOS Token id: 128001 and EOS Token: <|end_of_text|>\n","output_type":"stream"}]},{"cell_type":"code","source":"# LoRA\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:23:31.825158Z","iopub.execute_input":"2024-07-19T03:23:31.825572Z","iopub.status.idle":"2024-07-19T03:23:36.513461Z","shell.execute_reply.started":"2024-07-19T03:23:31.825543Z","shell.execute_reply":"2024-07-19T03:23:36.512686Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\n\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\n\ntrain_data = alpaca_nepali_train #Change it to Hindi\ntrain_data = train_data.map(formatting_prompts_func, batched = True,)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:23:46.025662Z","iopub.execute_input":"2024-07-19T03:23:46.026003Z","iopub.status.idle":"2024-07-19T03:23:47.835774Z","shell.execute_reply.started":"2024-07-19T03:23:46.025978Z","shell.execute_reply":"2024-07-19T03:23:47.834851Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/41567 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a88b2e978d24e9a9db9c04d5c5d2311"}},"metadata":{}}]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = train_data,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        learning_rate = 2e-4,\n        fp16 = not torch.cuda.is_bf16_supported(),\n        bf16 = torch.cuda.is_bf16_supported(),\n        logging_steps = 100,\n        save_steps=500,                 ### Checkpoint will be save after every 500 steps\n        optim = \"adamw_8bit\",\n#         num_train_epochs=2,\n        max_steps = 10392,\n        weight_decay = 0.01,\n        report_to=\"wandb\", \n        run_name=\"llama3_nep_alpaca_0714\", \n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs_alpaca_nep_0714\",   # Saving the checkpoints to outputs folder\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T05:44:28.261792Z","iopub.execute_input":"2024-07-10T05:44:28.262171Z","iopub.status.idle":"2024-07-10T05:44:28.515721Z","shell.execute_reply.started":"2024-07-10T05:44:28.262138Z","shell.execute_reply":"2024-07-10T05:44:28.514814Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"#train_data = 10,392\ntrainer_stats = trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T05:44:31.026356Z","iopub.execute_input":"2024-07-10T05:44:31.027013Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 41,567 | Num Epochs = 2\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 10,392\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='379' max='10392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  379/10392 51:18 < 22:42:42, 0.12 it/s, Epoch 0.07/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.808700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.976700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.945900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import wandb\n# run = wandb.init()\n# artifact = run.use_artifact('icodeformybhasa/llama-finetune-nepali-alpaca/model-lively-wildflower-10:v9', type='model')\n# artifact_dir = artifact.download()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:24:03.124034Z","iopub.execute_input":"2024-07-19T03:24:03.124885Z","iopub.status.idle":"2024-07-19T03:24:22.145980Z","shell.execute_reply.started":"2024-07-19T03:24:03.124853Z","shell.execute_reply":"2024-07-19T03:24:22.144925Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mssdhakal57\u001b[0m (\u001b[33micodeformybhasa\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240719_032403-r15vgr1t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/icodeformybhasa/llama-finetune-nepali-alpaca/runs/r15vgr1t' target=\"_blank\">fallen-darkness-11</a></strong> to <a href='https://wandb.ai/icodeformybhasa/llama-finetune-nepali-alpaca' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/icodeformybhasa/llama-finetune-nepali-alpaca' target=\"_blank\">https://wandb.ai/icodeformybhasa/llama-finetune-nepali-alpaca</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/icodeformybhasa/llama-finetune-nepali-alpaca/runs/r15vgr1t' target=\"_blank\">https://wandb.ai/icodeformybhasa/llama-finetune-nepali-alpaca/runs/r15vgr1t</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-lively-wildflower-10:v9, 250.58MB. 11 files... \n\u001b[34m\u001b[1mwandb\u001b[0m:   11 of 11 files downloaded.  \nDone. 0:0:2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# import shutil\n# import os\n\n# def copy_files(src_dir, dst_dir):\n\n#     os.makedirs(dst_dir, exist_ok=True)\n\n#     file_names = os.listdir(src_dir)\n\n#     if not os.listdir(dst_dir):\n#         for file_name in file_names:\n#             src_file = os.path.join(src_dir, file_name)\n#             dst_file = os.path.join(dst_dir, file_name)\n#             shutil.move(src_file, dst_file)\n#     else:\n#         print(\"Files have already been moved\")\n\n#     try:\n#         os.rmdir(src_dir)\n#     except OSError:\n#         shutil.rmtree(src_dir)\n\n# src_dir = artifact_dir\n# dst_dir = \"/kaggle/working/outputs/checkpoint-9900\"  \n\n# copy_files(src_dir, dst_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:24:29.276512Z","iopub.execute_input":"2024-07-19T03:24:29.277249Z","iopub.status.idle":"2024-07-19T03:24:29.291184Z","shell.execute_reply.started":"2024-07-19T03:24:29.277200Z","shell.execute_reply":"2024-07-19T03:24:29.290040Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# from trl import SFTTrainer\n# from transformers import TrainingArguments\n\n# trainer = SFTTrainer(\n#     model = model,\n#     tokenizer = tokenizer,\n#     train_dataset = train_data,\n#     dataset_text_field = \"text\",\n#     max_seq_length = max_seq_length,\n#     dataset_num_proc = 2,\n#     packing = False, # Can make training 5x faster for short sequences.\n#     args = TrainingArguments(\n#         per_device_train_batch_size = 2,\n#         gradient_accumulation_steps = 4,\n#         warmup_steps = 5,\n#         learning_rate = 2e-4,\n#         fp16 = not torch.cuda.is_bf16_supported(),\n#         bf16 = torch.cuda.is_bf16_supported(),\n#         logging_steps = 100,\n#         save_steps=500,                 ### Checkpoint will be save after every 500 steps\n#         optim = \"adamw_8bit\",\n# #         num_train_epochs=2,\n#         max_steps = 10392,\n#         weight_decay = 0.01,\n#         report_to=\"wandb\", \n#         run_name=\"llama3_nep_alpaca_0714_9900\", \n#         lr_scheduler_type = \"linear\",\n#         seed = 3407,\n#         output_dir = \"outputs\",\n#     ),\n# )","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:24:34.878871Z","iopub.execute_input":"2024-07-19T03:24:34.879220Z","iopub.status.idle":"2024-07-19T03:24:52.607671Z","shell.execute_reply.started":"2024-07-19T03:24:34.879190Z","shell.execute_reply":"2024-07-19T03:24:52.606649Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/41567 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c5591c2c714ed295efdf2f0dd67621"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"# trainer_stats = trainer.train(resume_from_checkpoint = True)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:25:00.282677Z","iopub.execute_input":"2024-07-19T03:25:00.283047Z","iopub.status.idle":"2024-07-19T05:36:08.005784Z","shell.execute_reply.started":"2024-07-19T03:25:00.283014Z","shell.execute_reply":"2024-07-19T05:36:08.004914Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 41,567 | Num Epochs = 2\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 10,392\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10392' max='10392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10392/10392 2:10:51, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>9600</td>\n      <td>0.611200</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>0.618400</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>0.627700</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>0.619000</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.605300</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>0.607200</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>0.600700</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>0.605400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs/checkpoint-10000)... Done. 0.8s\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs/checkpoint-10392)... Done. 0.8s\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T05:36:11.394572Z","iopub.execute_input":"2024-07-19T05:36:11.394825Z","iopub.status.idle":"2024-07-19T05:36:11.398846Z","shell.execute_reply.started":"2024-07-19T05:36:11.394802Z","shell.execute_reply":"2024-07-19T05:36:11.397992Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# hf_token = user_secrets.get_secret(\"HF_HUB\")","metadata":{"execution":{"iopub.status.busy":"2024-07-19T05:36:11.400054Z","iopub.execute_input":"2024-07-19T05:36:11.400681Z","iopub.status.idle":"2024-07-19T05:36:11.526232Z","shell.execute_reply.started":"2024-07-19T05:36:11.400647Z","shell.execute_reply":"2024-07-19T05:36:11.525595Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# # Save LoRA\n# model.push_to_hub(\"shreeyad/nep_llama-3_lora_model\", token = hf_token)\n# tokenizer.push_to_hub(\"shreeyad/nep_llama-3_lora_model\", token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T05:47:46.766004Z","iopub.execute_input":"2024-07-19T05:47:46.766661Z","iopub.status.idle":"2024-07-19T05:47:56.310795Z","shell.execute_reply.started":"2024-07-19T05:47:46.766617Z","shell.execute_reply":"2024-07-19T05:47:56.309823Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15fc1201aa2b4d5aa233baf91b0929ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8703d28b96049f4aa971005e21e689a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b677c57a3d4c2baf24ce02ecdffc6f"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/shreeyad/nep_llama-3_lora_model\n","output_type":"stream"}]},{"cell_type":"code","source":"# import tempfile\n\n# with tempfile.TemporaryDirectory() as tmp_dir:\n#     model.save_pretrained(tmp_dir)\n#     model.push_to_hub_merged(\"shreeyad/nep_llama-3_16bit_model\", tokenizer, save_method = \"merged_16bit\", token = hf_token, use_temp_dir=False)\n#This runs out of space in Kaggle so we will use colab to merge LoRA to the base model","metadata":{"execution":{"iopub.status.busy":"2024-07-19T06:24:34.629276Z","iopub.execute_input":"2024-07-19T06:24:34.630132Z","iopub.status.idle":"2024-07-19T06:24:34.634081Z","shell.execute_reply.started":"2024-07-19T06:24:34.630098Z","shell.execute_reply":"2024-07-19T06:24:34.633102Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# model.push_to_hub_merged(\"shreeyad/nep_llama-3_4bit_model\", tokenizer, save_method = \"merged_4bit_forced\", token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T06:21:32.982212Z","iopub.execute_input":"2024-07-19T06:21:32.982605Z","iopub.status.idle":"2024-07-19T06:24:16.105896Z","shell.execute_reply.started":"2024-07-19T06:21:32.982570Z","shell.execute_reply":"2024-07-19T06:24:16.104848Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 4bit...\nThis might take 5 minutes...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Done.\nUnsloth: Saving 4bit Bitsandbytes model. Please wait...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15d564718a2843e9a5784acf6d5d84b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eea4f2c4bdc4e6688efcf3598c0b992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd31f799f984a719d16ecd30f15d6d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08a130620a4a4dccb157837697220db8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/581 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1996bc0d2feb4f668abe83d73ad14768"}},"metadata":{}},{"name":"stdout","text":"Saved merged_4bit model to https://huggingface.co/shreeyad/nep_llama-3_4bit_model\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf _unsloth_temporary_saved_buffers","metadata":{"execution":{"iopub.status.busy":"2024-07-19T06:21:30.505712Z","iopub.execute_input":"2024-07-19T06:21:30.506830Z","iopub.status.idle":"2024-07-19T06:21:31.579239Z","shell.execute_reply.started":"2024-07-19T06:21:30.506780Z","shell.execute_reply":"2024-07-19T06:21:31.577762Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# !du -h --max-depth=1 /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2024-07-19T06:17:22.437346Z","iopub.execute_input":"2024-07-19T06:17:22.438065Z","iopub.status.idle":"2024-07-19T06:17:23.509411Z","shell.execute_reply.started":"2024-07-19T06:17:22.438030Z","shell.execute_reply":"2024-07-19T06:17:23.508288Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"14G\t/kaggle/working/_unsloth_temporary_saved_buffers\n6.6G\t/kaggle/working/nep_llama-3_16bit_model\n20G\t/kaggle/working\n","output_type":"stream"}]}]}