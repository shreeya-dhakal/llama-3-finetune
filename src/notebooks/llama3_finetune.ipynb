{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Fine-tune multi-lingual - with both Hindi and Nepali\n- Fine tune with Hindi run inference on Nepali \n- Fine tune with Nepali run inference on Hindi\n- Fine tune with Nepali run inference on Nepali\n- Fine tune with Hindi run inference on Hindi","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:48:41.007287Z","iopub.execute_input":"2024-07-15T01:48:41.008093Z","iopub.status.idle":"2024-07-15T01:48:41.023683Z","shell.execute_reply.started":"2024-07-15T01:48:41.008059Z","shell.execute_reply":"2024-07-15T01:48:41.022693Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"GITHUB_KEY\")","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:48:42.394511Z","iopub.execute_input":"2024-07-15T01:48:42.394892Z","iopub.status.idle":"2024-07-15T01:48:42.548537Z","shell.execute_reply.started":"2024-07-15T01:48:42.394864Z","shell.execute_reply":"2024-07-15T01:48:42.547842Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!git clone https://{token}@github.com/shreeya-dhakal/llama-3-finetune.git","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:48:43.958359Z","iopub.execute_input":"2024-07-15T01:48:43.959096Z","iopub.status.idle":"2024-07-15T01:48:48.260172Z","shell.execute_reply.started":"2024-07-15T01:48:43.959065Z","shell.execute_reply":"2024-07-15T01:48:48.259207Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'llama-3-finetune'...\nremote: Enumerating objects: 132, done.\u001b[K\nremote: Counting objects: 100% (132/132), done.\u001b[K\nremote: Compressing objects: 100% (105/105), done.\u001b[K\nremote: Total 132 (delta 65), reused 74 (delta 19), pack-reused 0\u001b[K\nReceiving objects: 100% (132/132), 27.96 MiB | 18.88 MiB/s, done.\nResolving deltas: 100% (65/65), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!mamba install --force-reinstall aiohttp -y\n!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:48:48.494141Z","iopub.execute_input":"2024-07-15T01:48:48.494504Z","iopub.status.idle":"2024-07-15T01:53:38.998783Z","shell.execute_reply.started":"2024-07-15T01:48:48.494473Z","shell.execute_reply":"2024-07-15T01:53:38.997451Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport wandb\n\nos.environ[\"WANDB_PROJECT\"]=\"llama-finetune-nepali\"\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\nwandb_token = user_secrets.get_secret(\"WANDB_KEY\")\nwandb.login(key= wandb_token)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:53:39.001118Z","iopub.execute_input":"2024-07-15T01:53:39.002034Z","iopub.status.idle":"2024-07-15T01:53:41.996351Z","shell.execute_reply.started":"2024-07-15T01:53:39.001993Z","shell.execute_reply":"2024-07-15T01:53:41.995639Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric, concatenate_datasets\nimport sys\nimport os\nsys.path.append('/kaggle/working/llama-3-finetune/src/')\nfrom data.data_sampler import sample_data\nfrom unsloth import FastLanguageModel\nimport torch\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:58:11.072556Z","iopub.execute_input":"2024-07-15T01:58:11.073559Z","iopub.status.idle":"2024-07-15T01:58:11.079006Z","shell.execute_reply.started":"2024-07-15T01:58:11.073525Z","shell.execute_reply":"2024-07-15T01:58:11.078046Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"split_ratio = 0.2\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:58:40.437600Z","iopub.execute_input":"2024-07-15T01:58:40.438450Z","iopub.status.idle":"2024-07-15T01:58:40.442410Z","shell.execute_reply.started":"2024-07-15T01:58:40.438413Z","shell.execute_reply":"2024-07-15T01:58:40.441338Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"CohereForAI/aya_dataset\"\naya_dataset = load_dataset(dataset_name)\ndataset_type = \"aya\"","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:58:42.817447Z","iopub.execute_input":"2024-07-15T01:58:42.818351Z","iopub.status.idle":"2024-07-15T01:58:50.564664Z","shell.execute_reply.started":"2024-07-15T01:58:42.818316Z","shell.execute_reply":"2024-07-15T01:58:50.563566Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/13.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8574c1c553402ab71db07c83464ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/137M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9326eda623e423eb549ddaaef5b3020"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/978k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c9a1e343ce45d7bd0759c703bbd590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3a0e4c8b454f6ab3ae420995a3ec0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becdc85d95bb45e0bc0d8d700e690ed9"}},"metadata":{}}]},{"cell_type":"code","source":"lang_multi = \"Nepali\"\naya_nepali_train, _ = sample_data(dataset_name, dataset_type, split_ratio, seed, output_dir=None, lang_multi=lang_multi)\naya_nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:58:50.566818Z","iopub.execute_input":"2024-07-15T01:58:50.567239Z","iopub.status.idle":"2024-07-15T01:58:56.358809Z","shell.execute_reply.started":"2024-07-15T01:58:50.567201Z","shell.execute_reply":"2024-07-15T01:58:56.357933Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4eee2c636ad4add86789f2926b2b5e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766ac217557f4461a8f77209ddda0a2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d437587af5ea472992d6063e1783f9ab"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n    num_rows: 3201\n})"},"metadata":{}}]},{"cell_type":"code","source":"lang_multi = \"Hindi\"\naya_hindi_train, _ = sample_data(dataset_name, dataset_type, split_ratio, seed, output_dir=None, lang_multi=lang_multi)\naya_hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:58:56.359896Z","iopub.execute_input":"2024-07-15T01:58:56.360189Z","iopub.status.idle":"2024-07-15T01:59:01.816989Z","shell.execute_reply.started":"2024-07-15T01:58:56.360163Z","shell.execute_reply":"2024-07-15T01:59:01.816054Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2405449642046cb9f409bc306d28c49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e1cdaee4a54813a905095bd584a48b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1153 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d25f03e0ba842f3b769529583941006"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n    num_rows: 922\n})"},"metadata":{}}]},{"cell_type":"code","source":"aya_nepali_train = aya_nepali_train.rename_columns(\n            {\"inputs\": \"input\", \"targets\": \"output\"})\nnew_column_data = [\"\"] * len(aya_nepali_train)  # Create a list with the same length as the dataset\naya_nepali_train = aya_nepali_train.add_column(\"instruction\", new_column_data)\naya_nepali_train = aya_nepali_train.remove_columns(['language', 'language_code', 'annotation_type', 'user_id'])\naya_nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:01.819844Z","iopub.execute_input":"2024-07-15T01:59:01.820147Z","iopub.status.idle":"2024-07-15T01:59:02.069217Z","shell.execute_reply.started":"2024-07-15T01:59:01.820121Z","shell.execute_reply":"2024-07-15T01:59:02.068180Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/3201 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81b72b093320422cbfa0e3139c8656ba"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 3201\n})"},"metadata":{}}]},{"cell_type":"code","source":"aya_hindi_train = aya_hindi_train.rename_columns(\n            {\"inputs\": \"input\", \"targets\": \"output\"})\nnew_column_data = [\"\"] * len(aya_hindi_train)\naya_hindi_train = aya_hindi_train.add_column(\"instruction\", new_column_data)\naya_hindi_train = aya_hindi_train.remove_columns(['language', 'language_code', 'annotation_type', 'user_id'])\naya_hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:02.070470Z","iopub.execute_input":"2024-07-15T01:59:02.070816Z","iopub.status.idle":"2024-07-15T01:59:02.123696Z","shell.execute_reply.started":"2024-07-15T01:59:02.070790Z","shell.execute_reply":"2024-07-15T01:59:02.122780Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/922 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba3801e27384b9fb5b2fca75a4343c8"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 922\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_name = \"Saugatkafley/alpaca-nepali-sft\"","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:02.124754Z","iopub.execute_input":"2024-07-15T01:59:02.125007Z","iopub.status.idle":"2024-07-15T01:59:02.129058Z","shell.execute_reply.started":"2024-07-15T01:59:02.124985Z","shell.execute_reply":"2024-07-15T01:59:02.128155Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"alpaca_nepali_train, _ = sample_data(dataset_name, \"alpaca\", split_ratio, seed, output_dir=None, lang_multi=None)\nalpaca_nepali_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:02.130475Z","iopub.execute_input":"2024-07-15T01:59:02.130824Z","iopub.status.idle":"2024-07-15T01:59:09.383705Z","shell.execute_reply.started":"2024-07-15T01:59:02.130794Z","shell.execute_reply":"2024-07-15T01:59:09.382744Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"578a7f4464324f69937832e266ff00fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/18.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ef689f135894cd89691823f7f42be5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/52005 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b65418430a4a01953af8951c4304e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/52005 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a79475598a3f43ed990764a8fb1da6ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51963 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b8dab2c7bc64811bd63e480b3bf3575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51963 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2009eaecbe24a78ae71a592958291e7"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output', 'id'],\n    num_rows: 41567\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_name = \"iamshnoo/alpaca-cleaned-hindi\"","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:09.384985Z","iopub.execute_input":"2024-07-15T01:59:09.385837Z","iopub.status.idle":"2024-07-15T01:59:09.389713Z","shell.execute_reply.started":"2024-07-15T01:59:09.385798Z","shell.execute_reply":"2024-07-15T01:59:09.388735Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"alpaca_hindi_train, _ = sample_data(dataset_name, \"alpaca\", split_ratio, seed, output_dir=None, lang_multi=None)\nalpaca_hindi_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:09.392269Z","iopub.execute_input":"2024-07-15T01:59:09.392875Z","iopub.status.idle":"2024-07-15T01:59:16.742034Z","shell.execute_reply.started":"2024-07-15T01:59:09.392848Z","shell.execute_reply":"2024-07-15T01:59:16.741130Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"128f185c71714549b3cd7176c4ad3ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/31.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee20cd4ba6c24e82a81a5b5ea632f1e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f21041900e7401ab9f2a11a334981aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86f93b0b5cd94a9fba23c91fc2a67646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732f9fd427d049688ec23a97641c49a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a259dc3c1814e1f8d4f03b07faa9e63"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'instruction', 'output'],\n    num_rows: 41408\n})"},"metadata":{}}]},{"cell_type":"code","source":"nepali_train = concatenate_datasets([aya_nepali_train, alpaca_nepali_train])\nnepali_train = nepali_train.shuffle(seed=42)\nnepali_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:16.743378Z","iopub.execute_input":"2024-07-15T01:59:16.743787Z","iopub.status.idle":"2024-07-15T01:59:16.780185Z","shell.execute_reply.started":"2024-07-15T01:59:16.743752Z","shell.execute_reply":"2024-07-15T01:59:16.779322Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction', 'id'],\n    num_rows: 44768\n})"},"metadata":{}}]},{"cell_type":"code","source":"hindi_train = concatenate_datasets([aya_hindi_train, alpaca_hindi_train])\nhindi_train = hindi_train.shuffle(seed=42)\nhindi_train","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:16.781788Z","iopub.execute_input":"2024-07-15T01:59:16.782140Z","iopub.status.idle":"2024-07-15T01:59:16.814547Z","shell.execute_reply.started":"2024-07-15T01:59:16.782116Z","shell.execute_reply":"2024-07-15T01:59:16.813733Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 42330\n})"},"metadata":{}}]},{"cell_type":"code","source":"# both_train = concatenate_datasets([nepali_train, hindi_train])\n# both_train = both_train.shuffle(seed=42)\n# both_train","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:27:54.097038Z","iopub.execute_input":"2024-06-16T21:27:54.097298Z","iopub.status.idle":"2024-06-16T21:27:54.101014Z","shell.execute_reply.started":"2024-06-16T21:27:54.097276Z","shell.execute_reply":"2024-06-16T21:27:54.100143Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Nepali\nprompt = \"\"\"Below is an instruction in Nepali that describes a task, paired with an input also in Nepali that provides further context. Write a response in Nepali that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:16.815663Z","iopub.execute_input":"2024-07-15T01:59:16.816014Z","iopub.status.idle":"2024-07-15T01:59:16.821322Z","shell.execute_reply.started":"2024-07-15T01:59:16.815984Z","shell.execute_reply":"2024-07-15T01:59:16.820463Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)\n\ntokenizer.add_special_tokens({\"pad_token\": \"<|reserved_special_token_0|>\"})\nmodel.config.pad_token_id = tokenizer.pad_token_id\ntokenizer.padding_side = 'right'","metadata":{"execution":{"iopub.status.busy":"2024-07-15T01:59:17.082524Z","iopub.execute_input":"2024-07-15T01:59:17.083421Z","iopub.status.idle":"2024-07-15T02:00:31.331572Z","shell.execute_reply.started":"2024-07-15T01:59:17.083381Z","shell.execute_reply":"2024-07-15T02:00:31.330607Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9286fc32c7914ad78cd348e16c95c622"}},"metadata":{}},{"name":"stdout","text":"==((====))==  Unsloth: Fast Llama patching release 2024.7\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.25.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"743af91102ba444f9278c4d48322edda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e42ef6cca64f9cb54428de830e540a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f661c80db1b249cdb6952a9e4822b7b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fe2e0a2565348b8a37c15870a07fd4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/464 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f5e8b44df7f4419be90550d05525d43"}},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Pad Token id: {tokenizer.pad_token_id} and Pad Token: {tokenizer.pad_token}\")\nprint(f\"EOS Token id: {tokenizer.eos_token_id} and EOS Token: {tokenizer.eos_token}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:00:31.333371Z","iopub.execute_input":"2024-07-15T02:00:31.333730Z","iopub.status.idle":"2024-07-15T02:00:31.338534Z","shell.execute_reply.started":"2024-07-15T02:00:31.333700Z","shell.execute_reply":"2024-07-15T02:00:31.337687Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Pad Token id: 128002 and Pad Token: <|reserved_special_token_0|>\nEOS Token id: 128001 and EOS Token: <|end_of_text|>\n","output_type":"stream"}]},{"cell_type":"code","source":"#LoRA\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:00:31.339572Z","iopub.execute_input":"2024-07-15T02:00:31.339898Z","iopub.status.idle":"2024-07-15T02:00:39.441246Z","shell.execute_reply.started":"2024-07-15T02:00:31.339873Z","shell.execute_reply":"2024-07-15T02:00:39.440454Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\n\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\n\ntrain_data = nepali_train\ntrain_data = train_data.map(formatting_prompts_func, batched = True,)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:00:39.443598Z","iopub.execute_input":"2024-07-15T02:00:39.444277Z","iopub.status.idle":"2024-07-15T02:00:41.374105Z","shell.execute_reply.started":"2024-07-15T02:00:39.444241Z","shell.execute_reply":"2024-07-15T02:00:41.373124Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/44768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52271a9ce84e49eaa4c8e722a2ab536d"}},"metadata":{}}]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = train_data,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        learning_rate = 2e-4,\n        fp16 = not torch.cuda.is_bf16_supported(),\n        bf16 = torch.cuda.is_bf16_supported(),\n        logging_steps = 100,\n        save_steps=300,                 ### Checkpoint will be save after every 500 steps\n        optim = \"adamw_8bit\",\n        max_steps = 10392,\n        weight_decay = 0.01,\n        report_to=\"wandb\", \n        run_name=\"llama3_alpaca_nep\", \n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs_alpaca_nep\",   # Saving the checkpoints to outputs folder\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:03:38.590230Z","iopub.execute_input":"2024-07-15T02:03:38.590658Z","iopub.status.idle":"2024-07-15T02:03:56.124766Z","shell.execute_reply.started":"2024-07-15T02:03:38.590624Z","shell.execute_reply":"2024-07-15T02:03:56.123909Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/44768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"009206c6efb244328d0221d64e4fc9d4"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_stats = trainer.train()\n#train_data = 11192","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:03:57.626055Z","iopub.execute_input":"2024-07-15T02:03:57.627105Z","iopub.status.idle":"2024-07-15T02:05:20.126572Z","shell.execute_reply.started":"2024-07-15T02:03:57.627054Z","shell.execute_reply":"2024-07-15T02:05:20.125200Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 44,768 | Num Epochs = 2\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 10,392\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   10/10392 00:57 < 20:41:14, 0.14 it/s, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#train_data = 11192\u001b[39;00m\n","File \u001b[0;32m<string>:126\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n","File \u001b[0;32m<string>:363\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}